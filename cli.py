#!/usr/bin/env python3
"""
æ€æºç¬”è®°RAGçŸ¥è¯†åº“äº¤äº’å¼CLI
åŸºäºReAct Agentçš„äº¤äº’å¼é—®ç­”ç³»ç»Ÿ
"""

import asyncio
import os
import sys
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from utils.rag.rag_knowledge_base import create_rag_knowledge_base, create_rag_knowledge_base_with_openai
from utils.agent.react_agent import create_react_agent
from utils.logger import get_logger

logger = get_logger(__name__)


class SiYuanConnectionError(Exception):
    """æ€æºç¬”è®°è¿æ¥é”™è¯¯"""
    pass


async def check_siyuan_connection():
    """
    æ£€æŸ¥æ€æºç¬”è®°è¿æ¥æ˜¯å¦æ­£å¸¸

    Raises:
        SiYuanConnectionError: å½“æ— æ³•è¿æ¥åˆ°æ€æºç¬”è®°æ—¶æŠ›å‡º
    """
    try:
        # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹æ¥æ£€æŸ¥è¿æ¥
        rag_kb = create_knowledge_base()

        # å°è¯•è·å–ç¬”è®°æœ¬åˆ—è¡¨æ¥éªŒè¯è¿æ¥
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        logger.info(f"âœ… æ€æºç¬”è®°è¿æ¥æˆåŠŸï¼Œæ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬")

    except ConnectionError as e:
        error_msg = f"æ— æ³•è¿æ¥åˆ°æ€æºç¬”è®°: {e}"
        logger.error(error_msg)
        raise SiYuanConnectionError(error_msg)
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œè¿æ¥ç›¸å…³çš„é”™è¯¯
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in [
            "connection failed", "connect call failed", "connection refused",
            "timeout", "network", "host", "port", "ssl"
        ]):
            error_msg = f"æ€æºç¬”è®°ç½‘ç»œè¿æ¥å¤±è´¥: {e}"
            logger.error(error_msg)
            raise SiYuanConnectionError(error_msg)
        else:
            # å…¶ä»–ç±»å‹çš„é”™è¯¯ï¼Œé‡æ–°æŠ›å‡º
            raise


def create_knowledge_base(persist_directory_suffix: str = ""):
    """
    æ ¹æ®ç¯å¢ƒå˜é‡åˆ›å»ºçŸ¥è¯†åº“ï¼ˆä¸è‡ªåŠ¨æ„å»ºï¼‰

    Args:
        persist_directory_suffix: æŒä¹…åŒ–ç›®å½•åç¼€ï¼ˆå·²å¼ƒç”¨ï¼Œä¸ºä¿æŒå…¼å®¹æ€§ä¿ç•™ï¼‰

    Returns:
        RAGKnowledgeBase: çŸ¥è¯†åº“å®ä¾‹
    """
    # è·å–embeddingæ¨¡å‹é…ç½®
    embedding_model = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_BASE_URL")

    # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨OpenAI embeddingæ¨¡å‹
    is_openai_embedding = embedding_model.startswith("text-embedding-") or embedding_model in [
        "text-embedding-ada-002",
        "text-embedding-3-small",
        "text-embedding-3-large"
    ]

    # ä½¿ç”¨å›ºå®šçš„æŒä¹…åŒ–ç›®å½•
    persist_dir = "./data/rag_db"

    if is_openai_embedding:
        # ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹
        if not api_key:
            raise ValueError("ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹éœ€è¦è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")

        logger.info(f"åˆ›å»ºOpenAIåµŒå…¥çŸ¥è¯†åº“ï¼Œembeddingæ¨¡å‹: {embedding_model}")
        return create_rag_knowledge_base_with_openai(
            persist_directory=persist_dir,
            embedding_model=embedding_model,
            api_key=api_key,
            api_base=api_base,
            collection_name="siyuan_notes"
        )
    else:
        # ä½¿ç”¨æœ¬åœ°HuggingFaceåµŒå…¥æ¨¡å‹
        logger.info(f"åˆ›å»ºæœ¬åœ°åµŒå…¥çŸ¥è¯†åº“ï¼Œembeddingæ¨¡å‹: {embedding_model}")
        return create_rag_knowledge_base(
            persist_directory=persist_dir,
            embedding_model=embedding_model,
            use_openai_embedding=False,
            collection_name="siyuan_notes"
        )


async def select_notebook_and_build(rag_kb) -> bool:
    """
    è®©ç”¨æˆ·é€‰æ‹©ç¬”è®°æœ¬å¹¶æ„å»ºçŸ¥è¯†åº“

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹

    Returns:
        bool: æ˜¯å¦æˆåŠŸæ„å»º
    """
    try:
        # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
        print("ğŸ” æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
        await check_siyuan_connection()

        # è·å–ç¬”è®°æœ¬åˆ—è¡¨
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€æºç¬”è®°ç¬”è®°æœ¬")
            return False

        print(f"\nğŸ“š æ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬:")
        for i, (nb_id, nb_name) in enumerate(notebooks, 1):
            # æ£€æŸ¥è¯¥ç¬”è®°æœ¬æ˜¯å¦å·²æœ‰æ•°æ®
            existing_count = await rag_kb.get_notebook_document_count(nb_id)
            status = "âœ… å·²æ„å»º" if existing_count > 0 else "âŒ æœªæ„å»º"
            print(f"  {i}. {nb_name} (ID: {nb_id}) - {status} ({existing_count} ä¸ªæ–‡æ¡£å—)")

        print("\nè¯·é€‰æ‹©è¦æ„å»ºçŸ¥è¯†åº“çš„ç¬”è®°æœ¬:")
        try:
            choice = input("è¾“å…¥ç¬”è®°æœ¬ç¼–å· (å¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 1,2,3): ").strip()
            if not choice:
                print("âŒ æœªé€‰æ‹©ç¬”è®°æœ¬")
                return False

            # è§£æç”¨æˆ·é€‰æ‹©
            selected_indices = [int(x.strip()) - 1 for x in choice.split(",")]
            selected_notebooks = []

            for idx in selected_indices:
                if 0 <= idx < len(notebooks):
                    selected_notebooks.append(notebooks[idx])
                else:
                    print(f"âš ï¸ ç¼–å· {idx + 1} æ— æ•ˆï¼Œè·³è¿‡")

            if not selected_notebooks:
                print("âŒ æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆçš„ç¬”è®°æœ¬")
                return False

            # è·å–é…ç½®å‚æ•°
            chunk_size = int(os.getenv("RAG_CHUNK_SIZE", "1000"))
            chunk_overlap = int(os.getenv("RAG_CHUNK_OVERLAP", "200"))
            batch_size = int(os.getenv("RAG_BATCH_SIZE", "10"))

            # æ„å»ºé€‰å®šçš„ç¬”è®°æœ¬
            total_docs = 0
            success_count = 0
            failed_count = 0

            for nb_id, nb_name in selected_notebooks:
                print(f"\nğŸ“– å¼€å§‹æ„å»ºç¬”è®°æœ¬: {nb_name} (ID: {nb_id})")

                try:
                    # é¦–å…ˆæ‰“å¼€ç¬”è®°æœ¬
                    print(f"ğŸ”“ æ­£åœ¨æ‰“å¼€ç¬”è®°æœ¬: {nb_name}")
                    async with rag_kb.content_extractor.api_client:
                        await rag_kb.content_extractor.api_client.open_notebook(nb_id)
                    print(f"âœ… ç¬”è®°æœ¬ {nb_name} å·²æ‰“å¼€")

                    doc_count = await rag_kb.build_knowledge_base(
                        notebook_id=nb_id,
                        include_children=True,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap,
                        batch_size=batch_size,
                        force_rebuild=True  # ç”¨æˆ·ä¸»åŠ¨é€‰æ‹©ï¼Œå¼ºåˆ¶é‡å»º
                    )

                    total_docs += doc_count
                    success_count += 1
                    print(f"âœ… ç¬”è®°æœ¬ '{nb_name}' æ„å»ºå®Œæˆï¼Œå…± {doc_count} ä¸ªæ–‡æ¡£å—")

                except Exception as e:
                    failed_count += 1
                    print(f"âŒ æ„å»ºç¬”è®°æœ¬ '{nb_name}' å¤±è´¥: {e}")
                    logger.error(f"æ„å»ºç¬”è®°æœ¬å¤±è´¥: {e}")

            # æ˜¾ç¤ºæ„å»ºç»“æœæ€»ç»“
            if success_count > 0 and failed_count == 0:
                print(f"\nğŸ‰ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼æ€»è®¡ {total_docs} ä¸ªæ–‡æ¡£å—")
            elif success_count > 0 and failed_count > 0:
                print(f"\nâš ï¸ çŸ¥è¯†åº“æ„å»ºéƒ¨åˆ†å®Œæˆï¼æˆåŠŸ {success_count} ä¸ªç¬”è®°æœ¬ï¼Œå¤±è´¥ {failed_count} ä¸ªç¬”è®°æœ¬ï¼Œæ€»è®¡ {total_docs} ä¸ªæ–‡æ¡£å—")
            else:
                print(f"\nâŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼æ‰€æœ‰ {failed_count} ä¸ªç¬”è®°æœ¬æ„å»ºå¤±è´¥")

            return success_count > 0

        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—ç¼–å·")
            return False
        except KeyboardInterrupt:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False

    except Exception as e:
        print(f"âŒ é€‰æ‹©ç¬”è®°æœ¬å¤±è´¥: {e}")
        logger.error(f"é€‰æ‹©ç¬”è®°æœ¬å¤±è´¥: {e}")
        return False


async def check_existing_data_and_prompt(rag_kb):
    """
    æ£€æŸ¥ç°æœ‰æ•°æ®å¹¶æç¤ºç”¨æˆ·æ“ä½œé€‰æ‹©

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹

    Returns:
        str: æ“ä½œç±»å‹ ("rebuild", "incremental", "use_existing")
    """
    try:
        # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
        print("ğŸ” æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
        await check_siyuan_connection()

        # è·å–æ‰€æœ‰ç¬”è®°æœ¬
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            return True  # æ²¡æœ‰ç¬”è®°æœ¬ï¼Œéœ€è¦æ„å»º

        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰æ•°æ®
        total_existing = 0
        notebooks_with_data = []

        for nb_id, nb_name in notebooks:
            count = await rag_kb.get_notebook_document_count(nb_id)
            if count > 0:
                total_existing += count
                notebooks_with_data.append((nb_id, nb_name, count))

        if total_existing == 0:
            print("ğŸ†• æœªå‘ç°ç°æœ‰çŸ¥è¯†åº“æ•°æ®ï¼Œéœ€è¦åˆ›å»ºæ–°çš„çŸ¥è¯†åº“")
            return "rebuild"

        # æ˜¾ç¤ºç°æœ‰æ•°æ®çŠ¶æ€
        print(f"\nğŸ“Š å‘ç°ç°æœ‰çŸ¥è¯†åº“æ•°æ®:")
        print(f"æ€»æ–‡æ¡£å—æ•°: {total_existing}")
        print(f"å·²æ„å»ºçš„ç¬”è®°æœ¬:")
        for nb_id, nb_name, count in notebooks_with_data:
            print(f"  - {nb_name} (ID: {nb_id}): {count} ä¸ªæ–‡æ¡£å—")

        # è¯¢é—®ç”¨æˆ·æ˜¯å¦é‡å»ºæˆ–å¢é‡æ›´æ–°
        print("\nè¯·é€‰æ‹©çŸ¥è¯†åº“æ“ä½œæ–¹å¼ï¼Ÿ")
        print("1. é‡æ–°æ„å»º (åˆ é™¤ç°æœ‰æ•°æ®ï¼Œé‡æ–°åˆ›å»º)")
        print("2. å¢é‡æ›´æ–° (åªæ›´æ–°æœ‰ä¿®æ”¹çš„æ–‡æ¡£)")
        print("3. ä½¿ç”¨ç°æœ‰æ•°æ® (ç›´æ¥è¿›å…¥ReAct Agentæ¨¡å¼)")

        while True:
            choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
            if choice == "1":
                print("ğŸ”„ é€‰æ‹©é‡æ–°æ„å»ºçŸ¥è¯†åº“")
                return "rebuild"
            elif choice == "2":
                print("ğŸ”„ é€‰æ‹©å¢é‡æ›´æ–°çŸ¥è¯†åº“")
                return "incremental"
            elif choice == "3":
                print("âœ… ä½¿ç”¨ç°æœ‰çŸ¥è¯†åº“æ•°æ®")
                return "use_existing"
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        logger.error(f"æ£€æŸ¥ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return "rebuild"  # å‡ºé”™æ—¶é»˜è®¤é‡å»º


async def select_notebook_for_incremental_update(rag_kb) -> bool:
    """
    è®©ç”¨æˆ·é€‰æ‹©ç¬”è®°æœ¬è¿›è¡Œå¢é‡æ›´æ–°

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹

    Returns:
        bool: æ˜¯å¦æˆåŠŸè¿›è¡Œå¢é‡æ›´æ–°
    """
    try:
        # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
        print("ğŸ” æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
        await check_siyuan_connection()

        # è·å–ç¬”è®°æœ¬åˆ—è¡¨
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€æºç¬”è®°ç¬”è®°æœ¬")
            return False

        # æ£€æŸ¥å“ªäº›ç¬”è®°æœ¬æœ‰ç°æœ‰æ•°æ®
        notebooks_with_data = []
        for nb_id, nb_name in notebooks:
            existing_count = await rag_kb.get_notebook_document_count(nb_id)
            if existing_count > 0:
                notebooks_with_data.append((nb_id, nb_name, existing_count))

        if not notebooks_with_data:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å·²æ„å»ºçš„ç¬”è®°æœ¬ï¼Œæ— æ³•è¿›è¡Œå¢é‡æ›´æ–°")
            print("   è¯·å…ˆä½¿ç”¨å®Œæ•´æ„å»ºæ¨¡å¼åˆ›å»ºçŸ¥è¯†åº“")
            return False

        print(f"\nğŸ“š æ‰¾åˆ° {len(notebooks_with_data)} ä¸ªå·²æ„å»ºçš„ç¬”è®°æœ¬:")
        for i, (nb_id, nb_name, count) in enumerate(notebooks_with_data, 1):
            print(f"  {i}. {nb_name} (ID: {nb_id}) - {count} ä¸ªæ–‡æ¡£å—")

        print("\nè¯·é€‰æ‹©è¦è¿›è¡Œå¢é‡æ›´æ–°çš„ç¬”è®°æœ¬:")
        try:
            choice = input("è¾“å…¥ç¬”è®°æœ¬ç¼–å· (å¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 1,2,3)ï¼Œç›´æ¥å›è½¦é€‰æ‹©æ‰€æœ‰ç¬”è®°æœ¬: ").strip()
            if not choice:
                print("ğŸ“‹ é€‰æ‹©æ‰€æœ‰ç¬”è®°æœ¬è¿›è¡Œå¢é‡æ›´æ–°")
                selected_notebooks = notebooks_with_data  # é€‰æ‹©æ‰€æœ‰ç¬”è®°æœ¬
            else:
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_indices = [int(x.strip()) - 1 for x in choice.split(",")]
                selected_notebooks = []

                for idx in selected_indices:
                    if 0 <= idx < len(notebooks_with_data):
                        selected_notebooks.append(notebooks_with_data[idx])
                    else:
                        print(f"âš ï¸ ç¼–å· {idx + 1} æ— æ•ˆï¼Œè·³è¿‡")

            if not selected_notebooks:
                print("âŒ æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆçš„ç¬”è®°æœ¬")
                return False

            # è·å–é…ç½®å‚æ•°
            chunk_size = int(os.getenv("RAG_CHUNK_SIZE", "1000"))
            chunk_overlap = int(os.getenv("RAG_CHUNK_OVERLAP", "200"))
            batch_size = int(os.getenv("RAG_BATCH_SIZE", "10"))

            # æ‰§è¡Œå¢é‡æ›´æ–°
            total_updated = 0
            success_count = 0
            failed_count = 0

            for nb_id, nb_name, existing_count in selected_notebooks:
                print(f"\nğŸ“– å¼€å§‹å¢é‡æ›´æ–°ç¬”è®°æœ¬: {nb_name} (ID: {nb_id})")
                print(f"   ç°æœ‰æ–‡æ¡£å—: {existing_count}")

                try:
                    # é¦–å…ˆæ‰“å¼€ç¬”è®°æœ¬
                    print(f"ğŸ”“ æ­£åœ¨æ‰“å¼€ç¬”è®°æœ¬: {nb_name}")
                    async with rag_kb.content_extractor.api_client:
                        await rag_kb.content_extractor.api_client.open_notebook(nb_id)
                    print(f"âœ… ç¬”è®°æœ¬ {nb_name} å·²æ‰“å¼€")

                    # æ‰§è¡Œå¢é‡æ›´æ–°
                    updated_count = await rag_kb.build_knowledge_base_incremental(
                        notebook_id=nb_id,
                        include_children=True,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap,
                        batch_size=batch_size
                    )

                    total_updated += updated_count
                    success_count += 1
                    print(f"âœ… ç¬”è®°æœ¬ '{nb_name}' å¢é‡æ›´æ–°å®Œæˆï¼Œæ›´æ–°äº† {updated_count} ä¸ªæ–‡æ¡£å—")

                except Exception as e:
                    failed_count += 1
                    print(f"âŒ å¢é‡æ›´æ–°ç¬”è®°æœ¬ '{nb_name}' å¤±è´¥: {e}")
                    logger.error(f"å¢é‡æ›´æ–°ç¬”è®°æœ¬å¤±è´¥: {e}")

            # æ˜¾ç¤ºæ›´æ–°ç»“æœæ€»ç»“
            if success_count > 0 and failed_count == 0:
                print(f"\nğŸ‰ å¢é‡æ›´æ–°å®Œæˆï¼æ€»è®¡æ›´æ–° {total_updated} ä¸ªæ–‡æ¡£å—")
            elif success_count > 0 and failed_count > 0:
                print(f"\nâš ï¸ å¢é‡æ›´æ–°éƒ¨åˆ†å®Œæˆï¼æˆåŠŸ {success_count} ä¸ªç¬”è®°æœ¬ï¼Œå¤±è´¥ {failed_count} ä¸ªç¬”è®°æœ¬ï¼Œæ€»è®¡æ›´æ–° {total_updated} ä¸ªæ–‡æ¡£å—")
            else:
                print(f"\nâŒ å¢é‡æ›´æ–°å¤±è´¥ï¼æ‰€æœ‰ {failed_count} ä¸ªç¬”è®°æœ¬æ›´æ–°å¤±è´¥")

            return success_count > 0

        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—ç¼–å·")
            return False
        except KeyboardInterrupt:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False

    except Exception as e:
        print(f"âŒ é€‰æ‹©ç¬”è®°æœ¬å¤±è´¥: {e}")
        logger.error(f"é€‰æ‹©ç¬”è®°æœ¬å¤±è´¥: {e}")
        return False


async def build_notebook_directly(rag_kb, notebook_id: str) -> bool:
    """
    ç›´æ¥æ„å»ºæŒ‡å®šç¬”è®°æœ¬

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹
        notebook_id: ç¬”è®°æœ¬ID

    Returns:
        bool: æ˜¯å¦æˆåŠŸæ„å»º
    """
    try:
        # è·å–ç¬”è®°æœ¬åˆ—è¡¨
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()

        # æŸ¥æ‰¾æŒ‡å®šç¬”è®°æœ¬
        target_notebook = None
        for nb_id, nb_name in notebooks:
            if nb_id == notebook_id:
                target_notebook = (nb_id, nb_name)
                break

        if not target_notebook:
            print(f"âŒ æœªæ‰¾åˆ°ç¬”è®°æœ¬ ID: {notebook_id}")
            return False

        nb_id, nb_name = target_notebook
        print(f"ğŸ“– å¼€å§‹æ„å»ºç¬”è®°æœ¬: {nb_name} (ID: {nb_id})")

        # é¦–å…ˆæ‰“å¼€ç¬”è®°æœ¬
        print(f"ğŸ”“ æ­£åœ¨æ‰“å¼€ç¬”è®°æœ¬: {nb_name}")
        async with rag_kb.content_extractor.api_client:
            await rag_kb.content_extractor.api_client.open_notebook(nb_id)
        print(f"âœ… ç¬”è®°æœ¬ {nb_name} å·²æ‰“å¼€")

        # ä½¿ç”¨é»˜è®¤å‚æ•°æ„å»º
        doc_count = await rag_kb.build_knowledge_base(
            notebook_id=nb_id,
            include_children=True,
            chunk_size=1000,
            chunk_overlap=200,
            batch_size=10,
            force_rebuild=True
        )

        print(f"âœ… ç¬”è®°æœ¬ '{nb_name}' æ„å»ºå®Œæˆï¼Œå…± {doc_count} ä¸ªæ–‡æ¡£å—")
        return doc_count > 0

    except Exception as e:
        print(f"âŒ æ„å»ºç¬”è®°æœ¬å¤±è´¥: {e}")
        logger.error(f"æ„å»ºç¬”è®°æœ¬å¤±è´¥: {e}")
        return False


async def interactive_cli(notebook_id: str = None, incremental_mode: bool = False):
    """äº¤äº’å¼CLIä¸»å‡½æ•°"""
    print("\n=== æ€æºç¬”è®°RAGçŸ¥è¯†åº“äº¤äº’å¼CLI ===")
    print("è¾“å…¥é—®é¢˜æ¥æµ‹è¯•ReAct Agentï¼Œè¾“å…¥ 'quit' é€€å‡º")

    # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹
    print("ğŸ”§ æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹...")
    rag_kb = create_knowledge_base()

    # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œç›´æ¥æ‰§è¡Œå¢é‡æ›´æ–°
    if incremental_mode:
        print("ğŸ”„ æ‰§è¡Œå¢é‡æ›´æ–°æ¨¡å¼")
        success = await select_notebook_for_incremental_update(rag_kb)
        if not success:
            print("âŒ å¢é‡æ›´æ–°å¤±è´¥ï¼Œé€€å‡ºCLI")
            return
    else:
        # æ£€æŸ¥ç°æœ‰æ•°æ®å¹¶è¯¢é—®ç”¨æˆ·
        action = await check_existing_data_and_prompt(rag_kb)

        if action == "rebuild":
            if notebook_id:
                # ç›´æ¥æ„å»ºæŒ‡å®šç¬”è®°æœ¬
                print(f"ğŸ”§ ç›´æ¥æ„å»ºç¬”è®°æœ¬ ID: {notebook_id}")
                success = await build_notebook_directly(rag_kb, notebook_id)
                if not success:
                    print("âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œé€€å‡ºCLI")
                    return
            else:
                # éœ€è¦é‡æ–°æ„å»ºï¼Œè®©ç”¨æˆ·é€‰æ‹©ç¬”è®°æœ¬
                success = await select_notebook_and_build(rag_kb)
                if not success:
                    print("âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œé€€å‡ºCLI")
                    return
        elif action == "incremental":
            # æ‰§è¡Œå¢é‡æ›´æ–°
            success = await select_notebook_for_incremental_update(rag_kb)
            if not success:
                print("âŒ å¢é‡æ›´æ–°å¤±è´¥ï¼Œé€€å‡ºCLI")
                return
        else:  # use_existing
            print("âœ… ä½¿ç”¨ç°æœ‰çŸ¥è¯†åº“æ•°æ®")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = rag_kb.get_collection_stats()
    print(f"\nğŸ“Š çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
    print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    # åˆ›å»ºAgent
    agent = create_react_agent(rag_kb, max_tool_calls=5)
    print("[SUCCESS] ReAct Agentåˆ›å»ºæˆåŠŸï¼Œå¯ä»¥å¼€å§‹æé—®äº†ï¼")

    while True:
        try:
            print("\n" + "="*80)
            print("[RAG] è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ (è¾“å…¥ 'quit' æˆ– 'é€€å‡º' ç»“æŸå¯¹è¯):")
            print("="*80)
            question = input("[?] ").strip()

            if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("\n[SYS] æ„Ÿè°¢ä½¿ç”¨æ€æºç¬”è®°RAGé—®ç­”ç³»ç»Ÿï¼Œå†è§ï¼")
                break

            if not question:
                print("[WARN] è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜")
                continue

            print("\n[PROCESSING] æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...")
            print(f"[QUESTION] {question}")
            print("-" * 80)

            response = await agent.query(question)

            print("\n" + "="*80)
            print("[ANSWER] ç­”æ¡ˆ")
            print("="*80)
            print(f"{response.answer}")

            print("\n[STATS] å¤„ç†ç»Ÿè®¡:")
            print(f"  [TOOLS] å·¥å…·è°ƒç”¨æ¬¡æ•°: {response.tool_calls_made}")
            print(f"  [REASON] æ¨ç†æ­¥æ•°: {len(response.reasoning)}")
            print(f"  [CONFIDENCE] ç½®ä¿¡åº¦: {response.final_confidence:.2%}")
            print(f"  [SOURCES] ä½¿ç”¨æ¥æºæ•°: {len(response.sources_used)}")

            if response.sources_used:
                print("\n[REFERENCES] ä¸»è¦å‚è€ƒæ¥æº:")
                for i, source in enumerate(response.sources_used[:5], 1):
                    similarity = source.get('similarity', 0)
                    print(f"  {i}. {source['title']}")
                    print(f"     [SIMILARITY] {similarity:.3f}")

            print("\n" + "="*80)

        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºCLI")
            break
        except Exception as e:
            print(f"å¤„ç†å¤±è´¥: {e}")
            logger.error(f"äº¤äº’å¼CLIå¤±è´¥: {e}")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æ€æºç¬”è®°RAGçŸ¥è¯†åº“äº¤äº’å¼CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # äº¤äº’å¼æ¨¡å¼
  python cli.py

  # ç›´æ¥æ„å»ºæŒ‡å®šç¬”è®°æœ¬
  python cli.py --notebook-id 20230602143452-yt2rrgb

  # å¢é‡æ›´æ–°æ¨¡å¼
  python cli.py --incremental

  # æ˜¾ç¤ºç¬”è®°æœ¬åˆ—è¡¨
  python cli.py --list-notebooks
        """
    )

    parser.add_argument(
        "--notebook-id",
        type=str,
        help="ç›´æ¥æ„å»ºæŒ‡å®šç¬”è®°æœ¬IDï¼Œè·³è¿‡äº¤äº’å¼é€‰æ‹©"
    )

    parser.add_argument(
        "--list-notebooks",
        action="store_true",
        help="æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„ç¬”è®°æœ¬åˆ—è¡¨"
    )

    parser.add_argument(
        "--incremental",
        action="store_true",
        help="å¯¹å·²æœ‰çŸ¥è¯†åº“è¿›è¡Œå¢é‡æ›´æ–°"
    )

    return parser.parse_args()


async def list_notebooks():
    """æ˜¾ç¤ºç¬”è®°æœ¬åˆ—è¡¨"""
    print("ğŸ“š æ€æºç¬”è®°ç¬”è®°æœ¬åˆ—è¡¨")
    print("=" * 60)

    try:
        rag_kb = create_knowledge_base()
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()

        if not notebooks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€æºç¬”è®°ç¬”è®°æœ¬")
            return

        print(f"æ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬:\n")

        for i, (nb_id, nb_name) in enumerate(notebooks, 1):
            print(f"{i}. {nb_name}")
            print(f"   ID: {nb_id}")
            print()

    except Exception as e:
        print(f"âŒ è·å–ç¬”è®°æœ¬åˆ—è¡¨å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # å¤„ç†åˆ—è¡¨ç¬”è®°æœ¬è¯·æ±‚
    if args.list_notebooks:
        await list_notebooks()
        return

    print("ğŸš€ æ€æºç¬”è®°RAGçŸ¥è¯†åº“äº¤äº’å¼CLI")
    print("=" * 60)

    # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
    print("ğŸ” æ­£åœ¨æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
    try:
        await check_siyuan_connection()
        print("âœ… æ€æºç¬”è®°è¿æ¥æ­£å¸¸")
    except SiYuanConnectionError as e:
        print(f"âŒ {e}")
        print("\nğŸ”§ è¯·ç¡®ä¿:")
        print("1. æ€æºç¬”è®°æ­£åœ¨è¿è¡Œ")
        print("2. ç«¯å£ 6806 å¯ä»¥è®¿é—®")
        print("3. ç¯å¢ƒå˜é‡ SIYUAN_API_TOKEN å·²æ­£ç¡®è®¾ç½®")
        print("\nç¨‹åºé€€å‡º")
        return
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ€æºç¬”è®°è¿æ¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print("\nç¨‹åºé€€å‡º")
        return

    print("\n" + "="*60)

    # æ˜¾ç¤ºå½“å‰é…ç½®
    embedding_model = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    openai_model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
    openai_api_key = os.getenv("OPENAI_API_KEY")

    print(f"ğŸ“‹ å½“å‰é…ç½®:")
    print(f"  - Embeddingæ¨¡å‹: {embedding_model}")
    print(f"  - OpenAIæ¨¡å‹: {openai_model}")
    print(f"  - API Base: {os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')}")
    print(f"  - API Key: {'å·²è®¾ç½®' if openai_api_key else 'æœªè®¾ç½®'}")

    # æ£€æŸ¥å¿…è¦çš„API Key
    if not openai_api_key:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("   å¦‚éœ€ä½¿ç”¨OpenAIåŠŸèƒ½ï¼Œè¯·è®¾ç½®è¯¥ç¯å¢ƒå˜é‡")

    # åˆ¤æ–­embeddingç±»å‹
    is_openai_embedding = embedding_model.startswith("text-embedding-") or embedding_model in [
        "text-embedding-ada-002",
        "text-embedding-3-small",
        "text-embedding-3-large"
    ]

    if is_openai_embedding and not openai_api_key:
        print("âŒ é”™è¯¯: ä½¿ç”¨OpenAI embeddingæ¨¡å‹éœ€è¦è®¾ç½®OPENAI_API_KEY")
        return

    # å¯åŠ¨äº¤äº’å¼CLI
    await interactive_cli(args.notebook_id, args.incremental)


if __name__ == "__main__":
    asyncio.run(main())