#!/usr/bin/env python3
"""
æ„å»ºæ€æºç¬”è®°RAGçŸ¥è¯†åº“
ä½¿ç”¨æŒ‡å®šçš„embeddingæ¨¡å‹æ„å»ºå‘é‡ç´¢å¼•
"""

import asyncio
import os
import sys
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from utils.rag.rag_knowledge_base import create_rag_knowledge_base, create_rag_knowledge_base_with_openai
from utils.logger import get_logger

logger = get_logger(__name__)


async def build_knowledge_base(notebook_id: Optional[str] = None,
                             force_rebuild: bool = False,
                             incremental: bool = False,
                             embedding_model: Optional[str] = None):
    """
    æ„å»ºçŸ¥è¯†åº“

    Args:
        notebook_id: ç¬”è®°æœ¬IDï¼Œå¦‚æœä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰ç¬”è®°æœ¬
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»º
        incremental: æ˜¯å¦ä½¿ç”¨å¢é‡æ›´æ–°æ¨¡å¼
        embedding_model: æŒ‡å®šembeddingæ¨¡å‹ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
    """
    # è·å–é…ç½®
    embedding_model = embedding_model or os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_BASE_URL")

    print("=" * 60)
    print("æ„å»ºæ€æºç¬”è®°RAGçŸ¥è¯†åº“")
    print("=" * 60)
    print(f"Embeddingæ¨¡å‹: {embedding_model}")
    print(f"API Base: {api_base or 'https://api.openai.com/v1'}")
    print(f"API Key: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
    print(f"å¼ºåˆ¶é‡å»º: {force_rebuild}")
    print(f"å¢é‡æ›´æ–°: {incremental}")

    # åˆ¤æ–­embeddingç±»å‹
    is_openai_embedding = embedding_model.startswith("text-embedding-") or embedding_model in [
        "text-embedding-ada-002",
        "text-embedding-3-small",
        "text-embedding-3-large"
    ]

    if is_openai_embedding and not api_key:
        print("âŒ é”™è¯¯: ä½¿ç”¨OpenAI embeddingæ¨¡å‹éœ€è¦è®¾ç½®OPENAI_API_KEY")
        return

    # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹
    try:
        if is_openai_embedding:
            print("ğŸ”§ ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹åˆ›å»ºçŸ¥è¯†åº“...")
            rag_kb = create_rag_knowledge_base_with_openai(
                persist_directory="./data/rag_db",
                embedding_model=embedding_model,
                api_key=api_key,
                api_base=api_base,
                collection_name="siyuan_notes"
            )
        else:
            print("ğŸ”§ ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹åˆ›å»ºçŸ¥è¯†åº“...")
            rag_kb = create_rag_knowledge_base(
                persist_directory="./data/rag_db",
                embedding_model=embedding_model,
                use_openai_embedding=False,
                collection_name="siyuan_notes"
            )

        print("âœ… çŸ¥è¯†åº“å®ä¾‹åˆ›å»ºæˆåŠŸ")

    except Exception as e:
        print(f"âŒ çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {e}")
        logger.error(f"çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {e}")
        return

    # è·å–ç¬”è®°æœ¬åˆ—è¡¨
    try:
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬”è®°æœ¬")
            return

        print(f"ğŸ“š æ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬:")
        for i, (nb_id, nb_name) in enumerate(notebooks, 1):
            print(f"  {i}. {nb_name} (ID: {nb_id})")

    except Exception as e:
        print(f"âŒ è·å–ç¬”è®°æœ¬åˆ—è¡¨å¤±è´¥: {e}")
        logger.error(f"è·å–ç¬”è®°æœ¬åˆ—è¡¨å¤±è´¥: {e}")
        return

    # é€‰æ‹©è¦å¤„ç†çš„ç¬”è®°æœ¬
    notebooks_to_process = []
    if notebook_id:
        # å¤„ç†æŒ‡å®šç¬”è®°æœ¬
        for nb_id, nb_name in notebooks:
            if nb_id == notebook_id:
                notebooks_to_process.append((nb_id, nb_name))
                break
        else:
            print(f"âŒ æœªæ‰¾åˆ°æŒ‡å®šçš„ç¬”è®°æœ¬ID: {notebook_id}")
            return
    else:
        # å¤„ç†æ‰€æœ‰ç¬”è®°æœ¬
        notebooks_to_process = notebooks

    # æ„å»ºçŸ¥è¯†åº“
    total_docs = 0
    for nb_id, nb_name in notebooks_to_process:
        print(f"\nğŸ“– å¤„ç†ç¬”è®°æœ¬: {nb_name} (ID: {nb_id})")

        try:
            if incremental and not force_rebuild:
                # ä½¿ç”¨å¢é‡æ›´æ–°
                print(f"ğŸ”„ ä½¿ç”¨å¢é‡æ›´æ–°æ¨¡å¼å¤„ç†ç¬”è®°æœ¬ '{nb_name}'")
                doc_count = await rag_kb.build_knowledge_base_incremental(
                    notebook_id=nb_id,
                    include_children=True,
                    chunk_size=1000,
                    chunk_overlap=200,
                    batch_size=10
                )
            else:
                # ä½¿ç”¨å®Œæ•´æ„å»º
                if force_rebuild:
                    print(f"ğŸ”§ å¼ºåˆ¶é‡å»ºç¬”è®°æœ¬ '{nb_name}'")
                else:
                    print(f"ğŸ“ æ„å»ºç¬”è®°æœ¬ '{nb_name}'")
                doc_count = await rag_kb.build_knowledge_base(
                    notebook_id=nb_id,
                    include_children=True,
                    chunk_size=1000,
                    chunk_overlap=200,
                    batch_size=10,
                    force_rebuild=force_rebuild
                )

            total_docs += doc_count
            print(f"âœ… ç¬”è®°æœ¬ '{nb_name}' å¤„ç†å®Œæˆï¼Œå…± {doc_count} ä¸ªæ–‡æ¡£å—")

        except Exception as e:
            print(f"âŒ å¤„ç†ç¬”è®°æœ¬ '{nb_name}' å¤±è´¥: {e}")
            logger.error(f"å¤„ç†ç¬”è®°æœ¬å¤±è´¥: {e}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢æ•´ä¸ªæµç¨‹

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š çŸ¥è¯†åº“æ„å»ºå®Œæˆ!")
    print(f"æ€»æ–‡æ¡£å—æ•°: {total_docs}")

    try:
        stats = rag_kb.get_collection_stats()
        print(f"é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
        print(f"æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 'N/A')}")
        print(f"æŒä¹…åŒ–ç›®å½•: {stats.get('persist_directory', 'N/A')}")
        print(f"Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

        # æ˜¾ç¤ºå„ç¬”è®°æœ¬ç»Ÿè®¡
        notebook_stats = await rag_kb.get_all_notebooks_stats()
        if notebook_stats:
            print(f"\nğŸ“š å„ç¬”è®°æœ¬æ–‡æ¡£æ•°é‡:")
            for nb_id, count in notebook_stats.items():
                # æ‰¾åˆ°ç¬”è®°æœ¬åç§°
                nb_name = next((name for nid, name in notebooks if nid == nb_id), nb_id)
                print(f"  - {nb_name}: {count} ä¸ªæ–‡æ¡£å—")

    except Exception as e:
        print(f"âš ï¸ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

    print(f"\nğŸ‰ çŸ¥è¯†åº“æ„å»ºå®Œæˆ! å¯ä»¥å¼€å§‹è¿›è¡ŒRAGæŸ¥è¯¢äº†ã€‚")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ„å»ºæ€æºç¬”è®°RAGçŸ¥è¯†åº“")
    parser.add_argument("--notebook", "-n", type=str, help="æŒ‡å®šç¬”è®°æœ¬IDï¼ˆä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰ç¬”è®°æœ¬ï¼‰")
    parser.add_argument("--force", "-f", action="store_true", help="å¼ºåˆ¶é‡å»ºç°æœ‰çŸ¥è¯†åº“")
    parser.add_argument("--incremental", "-i", action="store_true", help="ä½¿ç”¨å¢é‡æ›´æ–°æ¨¡å¼ï¼ˆåªæ›´æ–°å·²æœ‰RAGæ•°æ®ä¸”æœ‰ä¿®æ”¹çš„æ–‡æ¡£ï¼‰")
    parser.add_argument("--model", "-m", type=str, help="æŒ‡å®šembeddingæ¨¡å‹")

    args = parser.parse_args()

    await build_knowledge_base(
        notebook_id=args.notebook,
        force_rebuild=args.force,
        incremental=args.incremental,
        embedding_model=args.model
    )


if __name__ == "__main__":
    asyncio.run(main())