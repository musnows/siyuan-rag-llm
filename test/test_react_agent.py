#!/usr/bin/env python3
"""
ReAct Agentæµ‹è¯•è„šæœ¬
æµ‹è¯•åŸºäºReActæ¨¡å¼çš„æ™ºèƒ½AgentåŠŸèƒ½
"""

import asyncio
import os
import sys
import json
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.rag.rag_knowledge_base import create_rag_knowledge_base, create_rag_knowledge_base_with_openai
from utils.agent.react_agent import create_react_agent
from utils.agent.rag_tools import create_rag_toolkit
from utils.logger import get_logger

logger = get_logger(__name__)


class SiYuanConnectionError(Exception):
    """æ€æºç¬”è®°è¿æ¥é”™è¯¯"""
    pass


async def check_siyuan_connection():
    """
    æ£€æŸ¥æ€æºç¬”è®°è¿æ¥æ˜¯å¦æ­£å¸¸

    Raises:
        SiYuanConnectionError: å½“æ— æ³•è¿æ¥åˆ°æ€æºç¬”è®°æ—¶æŠ›å‡º
    """
    try:
        # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹æ¥æ£€æŸ¥è¿æ¥
        rag_kb = create_knowledge_base("connection_test")

        # å°è¯•è·å–ç¬”è®°æœ¬åˆ—è¡¨æ¥éªŒè¯è¿æ¥
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        logger.info(f"âœ… æ€æºç¬”è®°è¿æ¥æˆåŠŸï¼Œæ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬")

    except ConnectionError as e:
        error_msg = f"æ— æ³•è¿æ¥åˆ°æ€æºç¬”è®°: {e}"
        logger.error(error_msg)
        raise SiYuanConnectionError(error_msg)
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œè¿æ¥ç›¸å…³çš„é”™è¯¯
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in [
            "connection failed", "connect call failed", "connection refused",
            "timeout", "network", "host", "port", "ssl"
        ]):
            error_msg = f"æ€æºç¬”è®°ç½‘ç»œè¿æ¥å¤±è´¥: {e}"
            logger.error(error_msg)
            raise SiYuanConnectionError(error_msg)
        else:
            # å…¶ä»–ç±»å‹çš„é”™è¯¯ï¼Œé‡æ–°æŠ›å‡º
            raise


def create_knowledge_base(persist_directory_suffix: str = "", force_rebuild: bool = False):
    """
    æ ¹æ®ç¯å¢ƒå˜é‡åˆ›å»ºçŸ¥è¯†åº“ï¼ˆä¸è‡ªåŠ¨æ„å»ºï¼‰

    Args:
        persist_directory_suffix: æŒä¹…åŒ–ç›®å½•åç¼€
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºçŸ¥è¯†åº“ï¼ˆç”¨äºå¼‚æ­¥è°ƒç”¨ï¼‰

    Returns:
        RAGKnowledgeBase: çŸ¥è¯†åº“å®ä¾‹
    """
    # è·å–embeddingæ¨¡å‹é…ç½®
    embedding_model = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_BASE_URL")

    # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨OpenAI embeddingæ¨¡å‹
    is_openai_embedding = embedding_model.startswith("text-embedding-") or embedding_model in [
        "text-embedding-ada-002",
        "text-embedding-3-small",
        "text-embedding-3-large"
    ]

    if is_openai_embedding:
        # ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹
        if not api_key:
            raise ValueError("ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹éœ€è¦è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")

        persist_dir = f"./data/rag_db_openai_{persist_directory_suffix}" if persist_directory_suffix else "./data/rag_db_openai"

        logger.info(f"åˆ›å»ºOpenAIåµŒå…¥çŸ¥è¯†åº“ï¼Œembeddingæ¨¡å‹: {embedding_model}")
        return create_rag_knowledge_base_with_openai(
            persist_directory=persist_dir,
            embedding_model=embedding_model,
            api_key=api_key,
            api_base=api_base,
            collection_name=f"siyuan_notes_openai_{persist_directory_suffix}" if persist_directory_suffix else "siyuan_notes_openai"
        )
    else:
        # ä½¿ç”¨æœ¬åœ°HuggingFaceåµŒå…¥æ¨¡å‹
        persist_dir = f"./data/rag_db_local_{persist_directory_suffix}" if persist_directory_suffix else "./data/rag_db_local"

        logger.info(f"åˆ›å»ºæœ¬åœ°åµŒå…¥çŸ¥è¯†åº“ï¼Œembeddingæ¨¡å‹: {embedding_model}")
        return create_rag_knowledge_base(
            persist_directory=persist_dir,
            embedding_model=embedding_model,
            use_openai_embedding=False,
            collection_name=f"siyuan_notes_local_{persist_directory_suffix}" if persist_directory_suffix else "siyuan_notes_local"
        )


async def create_and_build_knowledge_base(persist_directory_suffix: str = "", force_rebuild: bool = False):
    """
    åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰

    Args:
        persist_directory_suffix: æŒä¹…åŒ–ç›®å½•åç¼€
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºçŸ¥è¯†åº“

    Returns:
        RAGKnowledgeBase: çŸ¥è¯†åº“å®ä¾‹
    """
    # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹
    rag_kb = create_knowledge_base(persist_directory_suffix, force_rebuild)

    # æ„å»ºçŸ¥è¯†åº“
    await build_knowledge_base_if_needed(rag_kb, force_rebuild)

    return rag_kb


async def select_notebook_and_build(rag_kb) -> bool:
    """
    è®©ç”¨æˆ·é€‰æ‹©ç¬”è®°æœ¬å¹¶æ„å»ºçŸ¥è¯†åº“

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹

    Returns:
        bool: æ˜¯å¦æˆåŠŸæ„å»º
    """
    try:
        # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
        print("ğŸ” æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
        await check_siyuan_connection()

        # è·å–ç¬”è®°æœ¬åˆ—è¡¨
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€æºç¬”è®°ç¬”è®°æœ¬")
            return False

        print(f"\nğŸ“š æ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬:")
        for i, (nb_id, nb_name) in enumerate(notebooks, 1):
            # æ£€æŸ¥è¯¥ç¬”è®°æœ¬æ˜¯å¦å·²æœ‰æ•°æ®
            existing_count = await rag_kb.get_notebook_document_count(nb_id)
            status = "âœ… å·²æ„å»º" if existing_count > 0 else "âŒ æœªæ„å»º"
            print(f"  {i}. {nb_name} (ID: {nb_id}) - {status} ({existing_count} ä¸ªæ–‡æ¡£å—)")

        print("\nè¯·é€‰æ‹©è¦æ„å»ºçŸ¥è¯†åº“çš„ç¬”è®°æœ¬:")
        try:
            choice = input("è¾“å…¥ç¬”è®°æœ¬ç¼–å· (å¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 1,2,3): ").strip()
            if not choice:
                print("âŒ æœªé€‰æ‹©ç¬”è®°æœ¬")
                return False

            # è§£æç”¨æˆ·é€‰æ‹©
            selected_indices = [int(x.strip()) - 1 for x in choice.split(",")]
            selected_notebooks = []

            for idx in selected_indices:
                if 0 <= idx < len(notebooks):
                    selected_notebooks.append(notebooks[idx])
                else:
                    print(f"âš ï¸ ç¼–å· {idx + 1} æ— æ•ˆï¼Œè·³è¿‡")

            if not selected_notebooks:
                print("âŒ æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆçš„ç¬”è®°æœ¬")
                return False

            # è¯¢é—®åˆ†å—å‚æ•°
            print("\nğŸ“‹ æ„å»ºå‚æ•°è®¾ç½® (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼):")
            chunk_size_input = input("æ–‡æ¡£åˆ†å—å¤§å° (é»˜è®¤1000): ").strip()
            chunk_overlap_input = input("åˆ†å—é‡å å¤§å° (é»˜è®¤200): ").strip()
            batch_size_input = input("æ‰¹å¤„ç†å¤§å° (é»˜è®¤10): ").strip()

            chunk_size = int(chunk_size_input) if chunk_size_input.isdigit() else 1000
            chunk_overlap = int(chunk_overlap_input) if chunk_overlap_input.isdigit() else 200
            batch_size = int(batch_size_input) if batch_size_input.isdigit() else 10

            print(f"\nğŸ”§ å°†ä½¿ç”¨å‚æ•°: åˆ†å—å¤§å°={chunk_size}, é‡å ={chunk_overlap}, æ‰¹å¤„ç†={batch_size}")

            # æ„å»ºé€‰å®šçš„ç¬”è®°æœ¬
            total_docs = 0
            for nb_id, nb_name in selected_notebooks:
                print(f"\nğŸ“– å¼€å§‹æ„å»ºç¬”è®°æœ¬: {nb_name} (ID: {nb_id})")

                try:
                    doc_count = await rag_kb.build_knowledge_base(
                        notebook_id=nb_id,
                        include_children=True,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap,
                        batch_size=batch_size,
                        force_rebuild=True  # ç”¨æˆ·ä¸»åŠ¨é€‰æ‹©ï¼Œå¼ºåˆ¶é‡å»º
                    )

                    total_docs += doc_count
                    print(f"âœ… ç¬”è®°æœ¬ '{nb_name}' æ„å»ºå®Œæˆï¼Œå…± {doc_count} ä¸ªæ–‡æ¡£å—")

                except Exception as e:
                    print(f"âŒ æ„å»ºç¬”è®°æœ¬ '{nb_name}' å¤±è´¥: {e}")
                    logger.error(f"æ„å»ºç¬”è®°æœ¬å¤±è´¥: {e}")

            print(f"\nğŸ‰ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼æ€»è®¡ {total_docs} ä¸ªæ–‡æ¡£å—")
            return total_docs > 0

        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—ç¼–å·")
            return False
        except KeyboardInterrupt:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False

    except Exception as e:
        print(f"âŒ é€‰æ‹©ç¬”è®°æœ¬å¤±è´¥: {e}")
        logger.error(f"é€‰æ‹©ç¬”è®°æœ¬å¤±è´¥: {e}")
        return False


async def check_existing_data_and_prompt(rag_kb) -> bool:
    """
    æ£€æŸ¥ç°æœ‰æ•°æ®å¹¶æç¤ºç”¨æˆ·æ˜¯å¦é‡å»º

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹

    Returns:
        bool: æ˜¯å¦éœ€è¦é‡æ–°æ„å»º
    """
    try:
        # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
        print("ğŸ” æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
        await check_siyuan_connection()

        # è·å–æ‰€æœ‰ç¬”è®°æœ¬
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            return True  # æ²¡æœ‰ç¬”è®°æœ¬ï¼Œéœ€è¦æ„å»º

        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰æ•°æ®
        total_existing = 0
        notebooks_with_data = []

        for nb_id, nb_name in notebooks:
            count = await rag_kb.get_notebook_document_count(nb_id)
            if count > 0:
                total_existing += count
                notebooks_with_data.append((nb_id, nb_name, count))

        if total_existing == 0:
            print("ğŸ†• æœªå‘ç°ç°æœ‰çŸ¥è¯†åº“æ•°æ®ï¼Œéœ€è¦åˆ›å»ºæ–°çš„çŸ¥è¯†åº“")
            return True

        # æ˜¾ç¤ºç°æœ‰æ•°æ®çŠ¶æ€
        print(f"\nğŸ“Š å‘ç°ç°æœ‰çŸ¥è¯†åº“æ•°æ®:")
        print(f"æ€»æ–‡æ¡£å—æ•°: {total_existing}")
        print(f"å·²æ„å»ºçš„ç¬”è®°æœ¬:")
        for nb_id, nb_name, count in notebooks_with_data:
            print(f"  - {nb_name} (ID: {nb_id}): {count} ä¸ªæ–‡æ¡£å—")

        # è¯¢é—®ç”¨æˆ·æ˜¯å¦é‡å»º
        print("\næ˜¯å¦è¦é‡æ–°æ„å»ºçŸ¥è¯†åº“ï¼Ÿ")
        print("1. é‡æ–°æ„å»º (åˆ é™¤ç°æœ‰æ•°æ®ï¼Œé‡æ–°åˆ›å»º)")
        print("2. ä½¿ç”¨ç°æœ‰æ•°æ® (ç›´æ¥è¿›å…¥ReAct Agentæ¨¡å¼)")

        while True:
            choice = input("è¯·é€‰æ‹© (1/2): ").strip()
            if choice == "1":
                print("ğŸ”„ é€‰æ‹©é‡æ–°æ„å»ºçŸ¥è¯†åº“")
                return True
            elif choice == "2":
                print("âœ… ä½¿ç”¨ç°æœ‰çŸ¥è¯†åº“æ•°æ®")
                return False
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        logger.error(f"æ£€æŸ¥ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return True  # å‡ºé”™æ—¶é»˜è®¤é‡å»º


async def build_knowledge_base_if_needed(rag_kb, force_rebuild: bool = False):
    """
    å¦‚æœéœ€è¦ï¼Œæ„å»ºçŸ¥è¯†åº“

    Args:
        rag_kb: çŸ¥è¯†åº“å®ä¾‹
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»º
    """
    try:
        # è·å–ç¬”è®°æœ¬åˆ—è¡¨
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        if not notebooks:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ç¬”è®°æœ¬ï¼Œè·³è¿‡çŸ¥è¯†åº“æ„å»º")
            return

        logger.info(f"æ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬ï¼Œå¼€å§‹æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€...")

        total_docs = 0
        for nb_id, nb_name in notebooks:
            # æ£€æŸ¥è¯¥ç¬”è®°æœ¬æ˜¯å¦å·²æœ‰æ•°æ®
            existing_count = await rag_kb.get_notebook_document_count(nb_id)

            if existing_count > 0 and not force_rebuild:
                logger.info(f"ç¬”è®°æœ¬ '{nb_name}' å·²æœ‰ {existing_count} ä¸ªæ–‡æ¡£å—ï¼Œè·³è¿‡æ„å»º")
                total_docs += existing_count
                continue

            if existing_count > 0 and force_rebuild:
                logger.info(f"å¼ºåˆ¶é‡å»ºç¬”è®°æœ¬ '{nb_name}' çš„æ•°æ® ({existing_count} ä¸ªæ–‡æ¡£å—)")

            # æ„å»ºè¯¥ç¬”è®°æœ¬çš„çŸ¥è¯†åº“
            logger.info(f"å¼€å§‹æ„å»ºç¬”è®°æœ¬ '{nb_name}' çš„çŸ¥è¯†åº“...")
            doc_count = await rag_kb.build_knowledge_base(
                notebook_id=nb_id,
                include_children=True,
                chunk_size=1000,
                chunk_overlap=200,
                batch_size=10,
                force_rebuild=force_rebuild
            )

            total_docs += doc_count
            logger.info(f"ç¬”è®°æœ¬ '{nb_name}' æ„å»ºå®Œæˆï¼Œå…± {doc_count} ä¸ªæ–‡æ¡£å—")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = rag_kb.get_collection_stats()
        logger.info(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼æ€»è®¡ {total_docs} ä¸ªæ–‡æ¡£å—")
        logger.info(f"é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
        logger.info(f"Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    except Exception as e:
        logger.error(f"æ„å»ºçŸ¥è¯†åº“å¤±è´¥: {e}")
        raise


async def test_rag_tools():
    """æµ‹è¯•RAGå·¥å…·åŠŸèƒ½"""
    print("\n=== ğŸ”§ æµ‹è¯•RAGå·¥å…·åŠŸèƒ½ ===")

    try:
        # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
        print("ğŸ” æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
        await check_siyuan_connection()
    except SiYuanConnectionError as e:
        print(f"âŒ {e}")
        print("è·³è¿‡RAGå·¥å…·æµ‹è¯•")
        return False

    # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹
    print("ğŸ”§ æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹...")
    rag_kb = create_knowledge_base("tools_test")

    # æ£€æŸ¥ç°æœ‰æ•°æ®
    stats = rag_kb.get_collection_stats()
    doc_count = stats.get('document_count', 0)

    if doc_count == 0:
        print("âŒ æœªå‘ç°çŸ¥è¯†åº“æ•°æ®ï¼Œéœ€è¦å…ˆæ„å»ºçŸ¥è¯†åº“")
        success = await select_notebook_and_build(rag_kb)
        if not success:
            print("âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œè·³è¿‡RAGå·¥å…·æµ‹è¯•")
            return False
    else:
        print(f"âœ… å‘ç°ç°æœ‰çŸ¥è¯†åº“æ•°æ®: {doc_count} ä¸ªæ–‡æ¡£å—")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
    print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    # è·å–ç¬”è®°æœ¬åˆ—è¡¨
    notebooks = rag_kb.content_extractor.workspace.list_notebooks()
    if not notebooks:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬”è®°æœ¬ï¼Œè·³è¿‡RAGå·¥å…·æµ‹è¯•")
        return False

    # é€‰æ‹©æœ‰æ•°æ®çš„ç¬”è®°æœ¬
    test_notebook_id = None
    for nb_id, nb_name in notebooks:
        count = await rag_kb.get_notebook_document_count(nb_id)
        if count > 0:
            test_notebook_id = nb_id
            print(f"âœ… é€‰æ‹©ç¬”è®°æœ¬: {nb_name} (ID: {nb_id}) - {count} ä¸ªæ–‡æ¡£å—")
            break

    if not test_notebook_id:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ…å«æ•°æ®çš„ç¬”è®°æœ¬")
        return False

    # åˆ›å»ºå·¥å…·åŒ…
    toolkit = create_rag_toolkit(rag_kb)

    # æµ‹è¯•æœç´¢å·¥å…·
    print("\n1ï¸âƒ£ æµ‹è¯•rag_searchå·¥å…·:")
    search_result = await toolkit.call_tool("rag_search", {
        "query": "æµ‹è¯•",
        "notebook_id": test_notebook_id,
        "max_results": 3
    })
    print(f"æœç´¢ç»“æœ: {json.dumps(search_result, ensure_ascii=False, indent=2)}")

    # æµ‹è¯•ç»Ÿè®¡å·¥å…·
    print("\n2ï¸âƒ£ æµ‹è¯•rag_get_statså·¥å…·:")
    stats_result = await toolkit.call_tool("rag_get_stats", {})
    print(f"ç»Ÿè®¡ç»“æœ: {json.dumps(stats_result, ensure_ascii=False, indent=2)}")

    # æµ‹è¯•å¤šæŸ¥è¯¢å·¥å…·
    print("\n3ï¸âƒ£ æµ‹è¯•rag_multi_queryå·¥å…·:")
    multi_result = await toolkit.call_tool("rag_multi_query", {
        "queries": ["æµ‹è¯•", "æ–‡æ¡£"],
        "notebook_id": test_notebook_id,
        "combine_strategy": "union"
    })
    print(f"å¤šæŸ¥è¯¢ç»“æœ: {json.dumps(multi_result, ensure_ascii=False, indent=2)}")

    return True


async def test_react_agent_simple():
    """æµ‹è¯•ReAct Agentç®€å•æŸ¥è¯¢"""
    print("\n=== æµ‹è¯•ReAct Agentç®€å•æŸ¥è¯¢ ===")

    # åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“
    print("æ­£åœ¨åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“...")
    rag_kb = await create_and_build_knowledge_base("simple_test")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = rag_kb.get_collection_stats()
    print(f"çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
    print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    # åˆ›å»ºAgent
    agent = create_react_agent(rag_kb, max_tool_calls=3)
    print("âœ… ReAct Agentåˆ›å»ºæˆåŠŸ")

    # è·å–ç¬”è®°æœ¬åˆ—è¡¨
    notebooks = rag_kb.content_extractor.workspace.list_notebooks()
    if not notebooks:
        print("æ²¡æœ‰æ‰¾åˆ°ç¬”è®°æœ¬ï¼Œè·³è¿‡Agentæµ‹è¯•")
        return False

    test_notebook_id = notebooks[0][0]
    print(f"ä½¿ç”¨ç¬”è®°æœ¬: {test_notebook_id}")

    # ç®€å•æµ‹è¯•é—®é¢˜
    test_questions = [
        "è¿™ä¸ªç¬”è®°æœ¬çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æŸ¥æ‰¾å…³äºæµ‹è¯•çš„æ–‡æ¡£",
        "æœ‰æ²¡æœ‰APIç›¸å…³çš„è¯´æ˜ï¼Ÿ"
    ]

    for i, question in enumerate(test_questions, 1):
        print(f"\n--- é—®é¢˜ {i}: {question} ---")

        try:
            response = await agent.query(question)

            print(f"ç­”æ¡ˆ: {response.answer}")
            print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {response.tool_calls_made}")
            print(f"ç½®ä¿¡åº¦: {response.final_confidence}")
            print(f"ä½¿ç”¨æ¥æºæ•°: {len(response.sources_used)}")

            # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
            print("\næ¨ç†è¿‡ç¨‹:")
            for j, step in enumerate(response.reasoning, 1):
                step_type_name = {
                    "thought": "æ€è€ƒ",
                    "action": "è¡ŒåŠ¨",
                    "observation": "è§‚å¯Ÿ"
                }.get(step.step_type, step.step_type)

                print(f"  {j}. {step_type_name}: {step.content[:100]}...")

            # æ˜¾ç¤ºæ¥æº
            if response.sources_used:
                print("\nä¸»è¦æ¥æº:")
                for source in response.sources_used[:3]:
                    print(f"  - {source['title']} (ç›¸ä¼¼åº¦: {source.get('similarity', 0):.3f})")

        except Exception as e:
            print(f"æŸ¥è¯¢å¤±è´¥: {e}")
            logger.error(f"ReAct AgentæŸ¥è¯¢å¤±è´¥: {e}")

    return True


async def test_react_agent_complex():
    """æµ‹è¯•ReAct Agentå¤æ‚æŸ¥è¯¢"""
    print("\n=== æµ‹è¯•ReAct Agentå¤æ‚æŸ¥è¯¢ ===")

    # åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“
    print("æ­£åœ¨åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“...")
    rag_kb = await create_and_build_knowledge_base("complex_test")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = rag_kb.get_collection_stats()
    print(f"çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
    print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    # åˆ›å»ºAgent
    agent = create_react_agent(rag_kb, max_tool_calls=5, max_steps=15)
    print("âœ… ReAct Agentåˆ›å»ºæˆåŠŸ")

    # è·å–ç¬”è®°æœ¬åˆ—è¡¨
    notebooks = rag_kb.content_extractor.workspace.list_notebooks()
    if not notebooks:
        print("æ²¡æœ‰æ‰¾åˆ°ç¬”è®°æœ¬ï¼Œè·³è¿‡å¤æ‚æŸ¥è¯¢æµ‹è¯•")
        return False

    test_notebook_id = notebooks[0][0]
    print(f"ä½¿ç”¨ç¬”è®°æœ¬: {test_notebook_id}")

    # å¤æ‚æµ‹è¯•é—®é¢˜
    complex_questions = [
        "è¯·æ€»ç»“è¿™ä¸ªç¬”è®°æœ¬ä¸­çš„æ‰€æœ‰é‡è¦æ¦‚å¿µå’Œå®šä¹‰",
        "æŸ¥æ‰¾å…³äºæ•°æ®å¤„ç†æµç¨‹çš„ç›¸å…³æ–‡æ¡£ï¼Œå¹¶è¯´æ˜å„ä¸ªæ­¥éª¤çš„ä½œç”¨",
        "è¿™ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨äº†å“ªäº›æŠ€æœ¯æ ˆï¼Ÿè¯·åˆ†åˆ«è¯´æ˜å®ƒä»¬çš„ä½œç”¨"
    ]

    for i, question in enumerate(complex_questions, 1):
        print(f"\n--- å¤æ‚é—®é¢˜ {i}: {question} ---")

        try:
            response = await agent.query(question)

            print(f"ç­”æ¡ˆ: {response.answer}")
            print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {response.tool_calls_made}")
            print(f"æ¨ç†æ­¥æ•°: {len(response.reasoning)}")
            print(f"ç½®ä¿¡åº¦: {response.final_confidence}")

            # åˆ†ææ¨ç†æ¨¡å¼
            thought_count = sum(1 for step in response.reasoning if step.step_type == "thought")
            action_count = sum(1 for step in response.reasoning if step.step_type == "action")
            observation_count = sum(1 for step in response.reasoning if step.step_type == "observation")

            print(f"æ¨ç†åˆ†æ: æ€è€ƒ {thought_count} æ¬¡, è¡ŒåŠ¨ {action_count} æ¬¡, è§‚å¯Ÿ {observation_count} æ¬¡")

            # æ˜¾ç¤ºè¯¦ç»†æ¨ç†è¿‡ç¨‹
            print("\nè¯¦ç»†æ¨ç†è¿‡ç¨‹:")
            for j, step in enumerate(response.reasoning, 1):
                step_type_name = {
                    "thought": "æ€è€ƒ",
                    "action": "è¡ŒåŠ¨",
                    "observation": "è§‚å¯Ÿ"
                }.get(step.step_type, step.step_type)

                print(f"\n{j}. [{step_type_name}] {step.content}")

                if step.tool_call:
                    print(f"   å·¥å…·è°ƒç”¨: {step.tool_call['name']}")
                    print(f"   å‚æ•°: {step.tool_call['arguments']}")

                if step.tool_result:
                    success = step.tool_result.get('success', False)
                    results_count = len(step.tool_result.get('results', []))
                    print(f"   ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}, ç»“æœæ•°é‡: {results_count}")

        except Exception as e:
            print(f"å¤æ‚æŸ¥è¯¢å¤±è´¥: {e}")
            logger.error(f"ReAct Agentå¤æ‚æŸ¥è¯¢å¤±è´¥: {e}")

    return True


async def test_react_agent_comparison():
    """å¯¹æ¯”æµ‹è¯•ReAct Agentå’Œä¼ ç»ŸAgent"""
    print("\n=== å¯¹æ¯”æµ‹è¯•ReAct Agentå’Œä¼ ç»ŸAgent ===")

    # åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“
    print("æ­£åœ¨åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“...")
    rag_kb = await create_and_build_knowledge_base("comparison_test")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = rag_kb.get_collection_stats()
    print(f"çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
    print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    # è·å–ç¬”è®°æœ¬åˆ—è¡¨
    notebooks = rag_kb.content_extractor.workspace.list_notebooks()
    if not notebooks:
        print("æ²¡æœ‰æ‰¾åˆ°ç¬”è®°æœ¬ï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")
        return False

    test_notebook_id = notebooks[0][0]

    # åˆ›å»ºReAct Agentå’Œä¼ ç»ŸAgent
    react_agent = create_react_agent(rag_kb, max_tool_calls=3)

    # å¯¼å…¥ä¼ ç»ŸAgent
    try:
        from utils.agent.rag_agent import create_rag_agent
        traditional_agent = create_rag_agent(rag_kb)
        use_traditional = True
    except Exception as e:
        print(f"æ— æ³•å¯¼å…¥ä¼ ç»ŸAgent: {e}")
        use_traditional = False

    # æµ‹è¯•é—®é¢˜
    test_question = "è¯·æ€»ç»“è¿™ä¸ªç¬”è®°æœ¬çš„ä¸»è¦å†…å®¹ï¼ŒåŒ…æ‹¬é‡è¦çš„æ¦‚å¿µå’Œæµç¨‹"

    print(f"æµ‹è¯•é—®é¢˜: {test_question}")

    # æµ‹è¯•ReAct Agent
    print("\n--- ReAct Agent å›ç­” ---")
    try:
        react_response = await react_agent.query(test_question)
        print(f"ReActç­”æ¡ˆ: {react_response.answer[:200]}...")
        print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {react_response.tool_calls_made}")
        print(f"ç½®ä¿¡åº¦: {react_response.final_confidence}")
        print(f"æ¨ç†æ­¥æ•°: {len(react_response.reasoning)}")
    except Exception as e:
        print(f"ReAct Agentå¤±è´¥: {e}")

    # æµ‹è¯•ä¼ ç»ŸAgent
    if use_traditional:
        print("\n--- ä¼ ç»ŸAgent å›ç­” ---")
        try:
            traditional_response = await traditional_agent.query(test_question, test_notebook_id)
            print(f"ä¼ ç»Ÿç­”æ¡ˆ: {traditional_response.answer[:200]}...")
            print(f"ç½®ä¿¡åº¦: {traditional_response.confidence}")
            print(f"æ¥æºæ•°é‡: {len(traditional_response.sources)}")
        except Exception as e:
            print(f"ä¼ ç»ŸAgentå¤±è´¥: {e}")

    return True


async def interactive_test():
    """äº¤äº’å¼æµ‹è¯•"""
    print("\n=== äº¤äº’å¼æµ‹è¯• ===")
    print("è¾“å…¥é—®é¢˜æ¥æµ‹è¯•ReAct Agentï¼Œè¾“å…¥ 'quit' é€€å‡º")

    # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹
    print("ğŸ”§ æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹...")
    rag_kb = create_knowledge_base("interactive_test")

    # æ£€æŸ¥ç°æœ‰æ•°æ®å¹¶è¯¢é—®ç”¨æˆ·
    need_rebuild = await check_existing_data_and_prompt(rag_kb)

    if need_rebuild:
        # éœ€è¦é‡æ–°æ„å»ºï¼Œè®©ç”¨æˆ·é€‰æ‹©ç¬”è®°æœ¬
        success = await select_notebook_and_build(rag_kb)
        if not success:
            print("âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return
    else:
        print("âœ… ä½¿ç”¨ç°æœ‰çŸ¥è¯†åº“æ•°æ®")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = rag_kb.get_collection_stats()
    print(f"\nğŸ“Š çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
    print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

    # åˆ›å»ºAgent
    agent = create_react_agent(rag_kb, max_tool_calls=5)
    print("âœ… ReAct Agentåˆ›å»ºæˆåŠŸï¼Œå¯ä»¥å¼€å§‹æé—®äº†ï¼")

    while True:
        try:
            question = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()

            if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                break

            if not question:
                continue

            print(f"\næ­£åœ¨å¤„ç†: {question}")
            print("-" * 50)

            response = await agent.query(question)

            print(f"\nç­”æ¡ˆ:\n{response.answer}")
            print(f"\nç»Ÿè®¡ä¿¡æ¯:")
            print(f"  - å·¥å…·è°ƒç”¨æ¬¡æ•°: {response.tool_calls_made}")
            print(f"  - æ¨ç†æ­¥æ•°: {len(response.reasoning)}")
            print(f"  - ç½®ä¿¡åº¦: {response.final_confidence}")
            print(f"  - ä½¿ç”¨æ¥æºæ•°: {len(response.sources_used)}")

            if response.sources_used:
                print(f"\nä¸»è¦æ¥æº:")
                for source in response.sources_used[:5]:
                    print(f"  - {source['title']} (ç›¸ä¼¼åº¦: {source.get('similarity', 0):.3f})")

        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºæµ‹è¯•")
            break
        except Exception as e:
            print(f"å¤„ç†å¤±è´¥: {e}")
            logger.error(f"äº¤äº’å¼æµ‹è¯•å¤±è´¥: {e}")


async def test_embedding_comparison():
    """å¯¹æ¯”æµ‹è¯•ä¸åŒembeddingæ¨¡å‹"""
    print("\n=== å¯¹æ¯”æµ‹è¯•ä¸åŒEmbeddingæ¨¡å‹ ===")

    # è·å–å½“å‰é…ç½®
    current_embedding_model = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    current_openai_model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")

    print(f"å½“å‰é…ç½®:")
    print(f"  - Embeddingæ¨¡å‹: {current_embedding_model}")
    print(f"  - OpenAIæ¨¡å‹: {current_openai_model}")
    print(f"  - API Base: {os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')}")

    # æµ‹è¯•æŸ¥è¯¢
    test_query = "æ€æºç¬”è®°çš„ä¸»è¦åŠŸèƒ½å’Œç‰¹ç‚¹"

    # åˆ›å»ºå½“å‰é…ç½®çš„çŸ¥è¯†åº“
    try:
        print(f"\næ­£åœ¨åˆ›å»ºå¹¶æ„å»ºçŸ¥è¯†åº“...")
        rag_kb = await create_and_build_knowledge_base("embedding_test")

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = rag_kb.get_collection_stats()
        print(f"çŸ¥è¯†åº“ä¿¡æ¯:")
        print(f"  - æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
        print(f"  - Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")

        agent = create_react_agent(rag_kb, max_tool_calls=3)

        print(f"\nä½¿ç”¨å½“å‰é…ç½®æµ‹è¯•:")
        print(f"æŸ¥è¯¢: {test_query}")

        response = await agent.query(test_query)

        print(f"âœ… æŸ¥è¯¢æˆåŠŸ!")
        print(f"ç­”æ¡ˆ: {response.answer[:200]}...")
        print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {response.tool_calls_made}")
        print(f"ç½®ä¿¡åº¦: {response.final_confidence}")
        print(f"ä½¿ç”¨æ¥æºæ•°: {len(response.sources_used)}")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"Embeddingå¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")

    return True


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æ€æºç¬”è®°RAGçŸ¥è¯†åº“ + ReAct Agent æµ‹è¯•ç¨‹åº")
    print("=" * 60)

    # é¦–å…ˆæ£€æŸ¥æ€æºç¬”è®°è¿æ¥
    print("ğŸ” æ­£åœ¨æ£€æŸ¥æ€æºç¬”è®°è¿æ¥...")
    try:
        await check_siyuan_connection()
        print("âœ… æ€æºç¬”è®°è¿æ¥æ­£å¸¸")
    except SiYuanConnectionError as e:
        print(f"âŒ {e}")
        print("\nğŸ”§ è¯·ç¡®ä¿:")
        print("1. æ€æºç¬”è®°æ­£åœ¨è¿è¡Œ")
        print("2. ç«¯å£ 6806 å¯ä»¥è®¿é—®")
        print("3. ç¯å¢ƒå˜é‡ SIYUAN_API_TOKEN å·²æ­£ç¡®è®¾ç½®")
        print("\nç¨‹åºé€€å‡º")
        return
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ€æºç¬”è®°è¿æ¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print("\nç¨‹åºé€€å‡º")
        return

    print("\n" + "="*60)

    # æ˜¾ç¤ºå½“å‰é…ç½®
    embedding_model = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    openai_model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
    openai_api_key = os.getenv("OPENAI_API_KEY")

    print(f"ğŸ“‹ å½“å‰é…ç½®:")
    print(f"  - Embeddingæ¨¡å‹: {embedding_model}")
    print(f"  - OpenAIæ¨¡å‹: {openai_model}")
    print(f"  - API Base: {os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')}")
    print(f"  - API Key: {'å·²è®¾ç½®' if openai_api_key else 'æœªè®¾ç½®'}")

    # æ£€æŸ¥å¿…è¦çš„API Key
    if not openai_api_key:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("   å¦‚éœ€ä½¿ç”¨OpenAIåŠŸèƒ½ï¼Œè¯·è®¾ç½®è¯¥ç¯å¢ƒå˜é‡")

    # åˆ¤æ–­embeddingç±»å‹
    is_openai_embedding = embedding_model.startswith("text-embedding-") or embedding_model in [
        "text-embedding-ada-002",
        "text-embedding-3-small",
        "text-embedding-3-large"
    ]

    if is_openai_embedding and not openai_api_key:
        print("âŒ é”™è¯¯: ä½¿ç”¨OpenAI embeddingæ¨¡å‹éœ€è¦è®¾ç½®OPENAI_API_KEY")
        return

    # æ˜¾ç¤ºèœå•
    print(f"\nğŸ“‹ è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. äº¤äº’å¼æµ‹è¯• (æ¨è)")
    print("2. è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    print("3. ä»…æµ‹è¯•RAGå·¥å…·")
    print("4. ä»…æµ‹è¯•ReAct Agent (ç®€å•)")
    print("5. ä»…æµ‹è¯•ReAct Agent (å¤æ‚)")
    print("6. Embeddingæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("0. é€€å‡º")

    while True:
        try:
            choice = input("\nè¯·é€‰æ‹© (0-6): ").strip()

            if choice == "0":
                print("ğŸ‘‹ é€€å‡ºç¨‹åº")
                break
            elif choice == "1":
                print("\nğŸ¯ å¯åŠ¨äº¤äº’å¼æµ‹è¯•...")
                await interactive_test()
                break
            elif choice == "2":
                print("\nğŸ§ª è¿è¡Œæ‰€æœ‰æµ‹è¯•...")
                await run_all_tests()
                break
            elif choice == "3":
                print("\nğŸ”§ æµ‹è¯•RAGå·¥å…·...")
                await test_rag_tools()
                break
            elif choice == "4":
                print("\nğŸ¤– æµ‹è¯•ReAct Agent (ç®€å•)...")
                await test_react_agent_simple()
                break
            elif choice == "5":
                print("\nğŸ¤– æµ‹è¯•ReAct Agent (å¤æ‚)...")
                await test_react_agent_complex()
                break
            elif choice == "6":
                print("\nğŸ“Š Embeddingæ¨¡å‹å¯¹æ¯”æµ‹è¯•...")
                await test_embedding_comparison()
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-6")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            break
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"æ‰§è¡Œæµ‹è¯•å¤±è´¥: {e}")


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    # æ£€æŸ¥æ€æºç¬”è®°è¿æ¥å’ŒçŸ¥è¯†åº“çŠ¶æ€
    try:
        print("\nğŸ” æ­£åœ¨æ£€æŸ¥æ€æºç¬”è®°è¿æ¥å’ŒçŸ¥è¯†åº“çŠ¶æ€...")
        await check_siyuan_connection()

        rag_kb = create_knowledge_base("main_test")
        notebooks = rag_kb.content_extractor.workspace.list_notebooks()
        stats = rag_kb.get_collection_stats()

        if not notebooks:
            print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æ€æºç¬”è®°ç¬”è®°æœ¬ï¼ŒæŸäº›æµ‹è¯•å¯èƒ½å¤±è´¥")
        else:
            print(f"âœ… æ‰¾åˆ° {len(notebooks)} ä¸ªç¬”è®°æœ¬")
            print(f"ğŸ“Š çŸ¥è¯†åº“çŠ¶æ€: {stats.get('document_count', 0)} ä¸ªæ–‡æ¡£å—")
            print(f"ğŸ”¤ Embeddingæ¨¡å‹: {stats.get('embedding_model', 'N/A')}")
    except SiYuanConnectionError as e:
        print(f"âŒ {e}")
        print("âŒ æ— æ³•è¿æ¥æ€æºç¬”è®°ï¼Œè·³è¿‡æ‰€æœ‰éœ€è¦æ€æºç¬”è®°çš„æµ‹è¯•")
        return
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ€æºç¬”è®°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print("âŒ è·³è¿‡æ‰€æœ‰æµ‹è¯•")
        return

    # è¿è¡Œæµ‹è¯•
    tests = [
        ("Embeddingæ¨¡å‹å¯¹æ¯”æµ‹è¯•", test_embedding_comparison),
        ("RAGå·¥å…·æµ‹è¯•", test_rag_tools),
        ("ReAct Agentç®€å•æŸ¥è¯¢æµ‹è¯•", test_react_agent_simple),
        ("ReAct Agentå¤æ‚æŸ¥è¯¢æµ‹è¯•", test_react_agent_complex),
        ("ReAct Agentå¯¹æ¯”æµ‹è¯•", test_react_agent_comparison)
    ]

    results = {}

    for test_name, test_func in tests:
        print(f"\n{'='*60}")
        print(f"ğŸ§ª è¿è¡Œ: {test_name}")
        print('='*60)

        try:
            result = await test_func()
            results[test_name] = "âœ… æˆåŠŸ" if result else "â­ï¸ è·³è¿‡"
            print(f"\n{test_name}: {'æˆåŠŸ' if result else 'è·³è¿‡'}")
        except Exception as e:
            results[test_name] = f"âŒ å¤±è´¥: {e}"
            print(f"\n{test_name} å¤±è´¥: {e}")
            logger.error(f"{test_name} å¤±è´¥: {e}")

        input("\nâ¸ï¸ æŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")

    # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print('='*60)

    for test_name, result in results.items():
        print(f"{test_name}: {result}")

    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())