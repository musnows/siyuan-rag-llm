# æ€æºç¬”è®°RAGçŸ¥è¯†åº“ç³»ç»Ÿ

åŸºäºæ€æºç¬”è®°çš„RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çŸ¥è¯†åº“ç³»ç»Ÿï¼Œæ”¯æŒä»æ€æºç¬”è®°è‡ªåŠ¨æ„å»ºå‘é‡çŸ¥è¯†åº“ï¼Œå¹¶æä¾›æ™ºèƒ½é—®ç­”åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ“š **è‡ªåŠ¨çŸ¥è¯†åº“æ„å»º**: ä»æ€æºç¬”è®°è‡ªåŠ¨æå–markdownå†…å®¹ï¼Œæ„å»ºå‘é‡ç´¢å¼•
- ğŸ” **æ™ºèƒ½æ£€ç´¢**: æ”¯æŒè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢å’Œå¤šæŸ¥è¯¢ç­–ç•¥
- ğŸ¤– **æ™ºèƒ½é—®ç­”**: é›†æˆOpenAI APIï¼ŒåŸºäºçŸ¥è¯†åº“å†…å®¹è¿›è¡Œæ™ºèƒ½é—®ç­”
- ğŸ“ **ä¸Šä¸‹æ–‡ç®¡ç†**: æ”¯æŒä¸Šä¸‹æ–‡å¢å¼ºæŸ¥è¯¢å’Œå¯¹è¯å†å²
- âš¡ **é«˜æ€§èƒ½**: æ”¯æŒæ‰¹é‡å¤„ç†å’Œæµå¼è¾“å‡º
- ğŸ”§ **å¯é…ç½®**: çµæ´»çš„å‚æ•°é…ç½®å’Œæ‰©å±•æ€§

## ç³»ç»Ÿæ¶æ„

```
æ€æºç¬”è®° â†’ å†…å®¹æå– â†’ æ–‡æ¡£åˆ†å— â†’ å‘é‡åŒ– â†’ ChromaDB
                                    â†“
ç”¨æˆ·æŸ¥è¯¢ â†’ ç›¸ä¼¼åº¦æ£€ç´¢ â†’ ä¸Šä¸‹æ–‡æ„å»º â†’ OpenAI API â†’ æ™ºèƒ½å›ç­”
```

## ç¯å¢ƒè¦æ±‚

- Python 3.13+
- æ€æºç¬”è®°ï¼ˆéœ€è¦å¼€å¯APIï¼‰
- OpenAI APIå¯†é’¥ï¼ˆç”¨äºæ™ºèƒ½é—®ç­”ï¼‰

## å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨uvå®‰è£…ä¾èµ–
uv sync

# æˆ–ä½¿ç”¨pip
pip install -e .
```

## ç¯å¢ƒé…ç½®

åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```env
# æ€æºç¬”è®°APIé…ç½®
SIYUAN_API_HOST=http://127.0.0.1:6806
SIYUAN_API_TOKEN=your_api_token_here

# OpenAI APIé…ç½®ï¼ˆç”¨äºæ™ºèƒ½é—®ç­”ï¼‰
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1  # å¯é€‰ï¼Œè‡ªå®šä¹‰APIåœ°å€
```

### è·å–æ€æºç¬”è®°API Token

1. æ‰“å¼€æ€æºç¬”è®°è®¾ç½® â†’ API â†’ ç”ŸæˆToken
2. ç¡®ä¿ API æœåŠ¡å·²å¯ç”¨ï¼ˆé»˜è®¤ç«¯å£ 6806ï¼‰
3. å¤åˆ¶ç”Ÿæˆçš„ Token åˆ°ç¯å¢ƒå˜é‡

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
import asyncio
from utils.siyuan.siyuan_content import create_content_extractor
from utils.rag.rag_knowledge_base import create_rag_knowledge_base
from utils.agent.rag_agent import create_rag_agent

async def main():
    # 1. è¿æ¥æ€æºç¬”è®°
    extractor = create_content_extractor()
    notebooks = extractor.workspace.list_notebooks()
    notebook_id = notebooks[0][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªç¬”è®°æœ¬

    # 2. æ„å»ºçŸ¥è¯†åº“
    rag_kb = create_rag_knowledge_base()
    doc_count = await rag_kb.build_knowledge_base(notebook_id)
    print(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå¤„ç†äº† {doc_count} ä¸ªæ–‡æ¡£å—")

    # 3. åˆ›å»ºæ™ºèƒ½Agent
    agent = create_rag_agent(rag_kb)

    # 4. æ™ºèƒ½é—®ç­”
    response = await agent.query(
        question="è¿™ä¸ªç¬”è®°æœ¬çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        notebook_id=notebook_id
    )
    print(f"å›ç­”: {response.answer}")
    print(f"ç½®ä¿¡åº¦: {response.confidence}")
    print(f"æ¥æº: {response.sources}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 2. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_rag_system.py

# è¿è¡Œä½¿ç”¨ç¤ºä¾‹
python example_usage.py
```

## è¯¦ç»†åŠŸèƒ½

### RAGçŸ¥è¯†åº“æ„å»º

```python
from utils.rag.rag_knowledge_base import create_rag_knowledge_base

# åˆ›å»ºçŸ¥è¯†åº“ï¼ˆè‡ªå®šä¹‰é…ç½®ï¼‰
rag_kb = create_rag_knowledge_base(
    persist_directory="./data/my_rag_db",  # æŒä¹…åŒ–ç›®å½•
    embedding_model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

# æ„å»ºçŸ¥è¯†åº“ï¼ˆé«˜çº§é…ç½®ï¼‰
doc_count = await rag_kb.build_knowledge_base(
    notebook_id="your_notebook_id",
    include_children=True,      # åŒ…å«å­ç¬”è®°
    chunk_size=1000,           # æ–‡æ¡£åˆ†å—å¤§å°
    chunk_overlap=200,         # åˆ†å—é‡å 
    batch_size=10              # æ‰¹å¤„ç†å¤§å°
)
```

### æ™ºèƒ½æ£€ç´¢

```python
from utils.rag.rag_query import create_query_engine

# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = create_query_engine(rag_kb)

# å•æŸ¥è¯¢
result = await query_engine.query(
    query_text="æœç´¢å…³é”®è¯",
    notebook_id="notebook_id",
    n_results=5
)

# å¤šæŸ¥è¯¢ç­–ç•¥
multi_result = await query_engine.multi_query(
    queries=["æ¦‚å¿µ", "å†…å®¹", "æ€»ç»“"],
    notebook_id="notebook_id",
    combine_strategy="union"  # union, intersection, weighted
)

# ä¸Šä¸‹æ–‡å¢å¼ºæŸ¥è¯¢
context_result = await query_engine.contextual_query(
    query_text="é—®é¢˜",
    notebook_id="notebook_id",
    context_note_ids=["note_id_1", "note_id_2"]
)
```

### æ™ºèƒ½Agent

```python
from utils.agent.rag_agent import create_rag_agent

# åˆ›å»ºAgentï¼ˆè‡ªå®šä¹‰é…ç½®ï¼‰
agent = create_rag_agent(
    knowledge_base=rag_kb,
    model="gpt-4",              # ä½¿ç”¨çš„æ¨¡å‹
    max_tokens=2000,            # æœ€å¤§ç”Ÿæˆtokenæ•°
    temperature=0.1,            # æ¸©åº¦å‚æ•°
    system_prompt="è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯"
)

# æ™®é€šé—®ç­”
response = await agent.query(
    question="æ‚¨çš„é—®é¢˜",
    notebook_id="notebook_id",
    context_strategy="simple"   # simple, contextual, multi_query
)

# æµå¼é—®ç­”
async for chunk in agent.stream_query(
    question="æ‚¨çš„é—®é¢˜",
    notebook_id="notebook_id"
):
    print(chunk, end="")

# å¯¹è¯å†å²ç®¡ç†
agent.clear_history()  # æ¸…ç©ºå†å²
summary = agent.get_conversation_summary()  # è·å–æ‘˜è¦
```

## é…ç½®å‚æ•°

### çŸ¥è¯†åº“é…ç½®

- `persist_directory`: å‘é‡æ•°æ®åº“æŒä¹…åŒ–ç›®å½•
- `embedding_model`: åµŒå…¥æ¨¡å‹ï¼ˆé»˜è®¤æ”¯æŒä¸­è‹±æ–‡ï¼‰
- `chunk_size`: æ–‡æ¡£åˆ†å—å¤§å°ï¼ˆé»˜è®¤1000å­—ç¬¦ï¼‰
- `chunk_overlap`: åˆ†å—é‡å å¤§å°ï¼ˆé»˜è®¤200å­—ç¬¦ï¼‰
- `batch_size`: æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤10ï¼‰

### æŸ¥è¯¢é…ç½®

- `max_context_length`: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé»˜è®¤4000å­—ç¬¦ï¼‰
- `similarity_threshold`: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼‰
- `max_documents`: æœ€å¤§æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤5ï¼‰

### Agenté…ç½®

- `model`: OpenAIæ¨¡å‹ï¼ˆé»˜è®¤gpt-3.5-turboï¼‰
- `max_tokens`: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆé»˜è®¤2000ï¼‰
- `temperature`: æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤0.1ï¼‰
- `use_streaming`: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤Falseï¼‰

## ä½¿ç”¨åœºæ™¯

1. **ä¸ªäººçŸ¥è¯†ç®¡ç†**: æ„å»ºä¸ªäººç¬”è®°çš„çŸ¥è¯†åº“ï¼Œå¿«é€Ÿæ£€ç´¢å’Œé—®ç­”
2. **ä¼ä¸šçŸ¥è¯†åº“**: åŸºäºä¼ä¸šæ–‡æ¡£æ„å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿ
3. **å­¦ä¹ è¾…åŠ©**: è‡ªåŠ¨æ€»ç»“å­¦ä¹ å†…å®¹ï¼Œå›ç­”ç›¸å…³é—®é¢˜
4. **ç ”ç©¶åŠ©æ‰‹**: å¿«é€Ÿæ£€ç´¢æ–‡çŒ®å†…å®¹ï¼Œç”Ÿæˆç ”ç©¶æ‘˜è¦

## æ³¨æ„äº‹é¡¹

1. **æ€æºç¬”è®°API**: ç¡®ä¿æ€æºç¬”è®°APIå·²å¯ç”¨å¹¶æ­£ç¡®é…ç½®
2. **ç½‘ç»œè¿æ¥**: é¦–æ¬¡ä½¿ç”¨åµŒå…¥æ¨¡å‹æ—¶éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶
3. **APIè´¹ç”¨**: ä½¿ç”¨OpenAI APIä¼šäº§ç”Ÿè´¹ç”¨ï¼Œè¯·æ³¨æ„æ§åˆ¶ä½¿ç”¨é‡
4. **æ€§èƒ½ä¼˜åŒ–**: å¤§é‡æ–‡æ¡£å»ºè®®åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **è¿æ¥æ€æºç¬”è®°å¤±è´¥**
   - æ£€æŸ¥æ€æºç¬”è®°æ˜¯å¦å¯åŠ¨
   - éªŒè¯API Tokenæ˜¯å¦æ­£ç¡®
   - ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸

2. **çŸ¥è¯†åº“æ„å»ºå¤±è´¥**
   - æ£€æŸ¥ç¬”è®°æœ¬ä¸­æ˜¯å¦æœ‰å†…å®¹
   - ç¡®è®¤æ–‡ä»¶æƒé™
   - æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

3. **Agentå›ç­”è´¨é‡å·®**
   - è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼
   - å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
   - ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯

4. **æ€§èƒ½é—®é¢˜**
   - å‡å°‘æ‰¹å¤„ç†å¤§å°
   - è°ƒæ•´åˆ†å—å‚æ•°
   - ä½¿ç”¨æ›´å¿«çš„åµŒå…¥æ¨¡å‹

### æ—¥å¿—è°ƒè¯•

```python
import logging
from utils.logger import get_logger

logger = get_logger(__name__)
logger.setLevel(logging.DEBUG)  # å¯ç”¨è¯¦ç»†æ—¥å¿—
```

## æ‰©å±•å¼€å‘

ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰æ‰©å±•ï¼š

1. **è‡ªå®šä¹‰åµŒå…¥æ¨¡å‹**: ç»§æ‰¿`RAGKnowledgeBase`ç±»
2. **è‡ªå®šä¹‰æŸ¥è¯¢ç­–ç•¥**: æ‰©å±•`RAGQueryEngine`ç±»
3. **è‡ªå®šä¹‰Agentè¡Œä¸º**: ç»§æ‰¿`RAGAgent`ç±»
4. **æ·»åŠ æ–°çš„æ•°æ®æº**: å®ç°`ContentExtractor`æ¥å£

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦è§ LICENSE æ–‡ä»¶ã€‚